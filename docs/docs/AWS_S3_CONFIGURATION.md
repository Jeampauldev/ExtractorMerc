# Configuraci√≥n AWS S3 para Producci√≥n

## Resumen

Esta gu√≠a describe los pasos necesarios para configurar AWS S3 en el sistema de post-procesamiento, incluyendo la creaci√≥n de bucket, configuraci√≥n de permisos, y activaci√≥n del servicio en producci√≥n.

## Estado Actual

- ‚úÖ **Servicio AWS S3 implementado** con modo simulado
- ‚úÖ **Tabla de registro `s3_files_registry` creada**
- ‚úÖ **Estructura organizacional definida**
- üîÑ **Pendiente:** Configuraci√≥n de credenciales para producci√≥n

## Estructura de Archivos en S3

```
Bucket: extractorov-data (configurable)
‚îÇ
‚îî‚îÄ‚îÄ raw_data/
    ‚îú‚îÄ‚îÄ RE2210202542239/
    ‚îÇ   ‚îú‚îÄ‚îÄ RE2210202542239_data_20251008_093221.json
    ‚îÇ   ‚îî‚îÄ‚îÄ RE2210202542239_data_20251008_093023.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ 63643842/
    ‚îÇ   ‚îî‚îÄ‚îÄ 63643842_data_20251008_124510.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ PQR_1_20251008_122537/
    ‚îÇ   ‚îî‚îÄ‚îÄ PQR_1_20251008_122537_data_20251008_122538.json
    ‚îÇ
    ‚îî‚îÄ‚îÄ misc_afinia/
        ‚îî‚îÄ‚îÄ archivos_sin_numero_reclamo.json
```

## Configuraci√≥n Paso a Paso

### 1. Crear Bucket S3

```bash
# AWS CLI
aws s3 mb s3://extractorov-data --region us-east-1

# O usar la consola de AWS
# https://s3.console.aws.amazon.com/s3/buckets
```

### 2. Crear Usuario IAM

**Nombre recomendado:** `extractorov-s3-uploader`

**Pol√≠tica JSON requerida:**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "ExtractorOVS3Access",
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:HeadObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::extractorov-data",
        "arn:aws:s3:::extractorov-data/*"
      ]
    },
    {
      "Sid": "ExtractorOVS3List", 
      "Effect": "Allow",
      "Action": [
        "s3:ListAllMyBuckets",
        "s3:GetBucketLocation"
      ],
      "Resource": "*"
    }
  ]
}
```

### 3. Obtener Credenciales

Despu√©s de crear el usuario IAM:

1. Ir a **IAM Console** ‚Üí **Users** ‚Üí `extractorov-s3-uploader`
2. Pesta√±a **Security credentials** 
3. **Create access key** ‚Üí **Application running outside AWS**
4. Guardar `Access Key ID` y `Secret Access Key`

### 4. Configurar Variables de Entorno

#### Opci√≥n A: Archivo .env
```bash
# config/env/.env
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=abc123...
AWS_REGION=us-east-1
AWS_S3_BUCKET_NAME=extractorov-data
S3_BASE_PATH=oficina-virtual
```

#### Opci√≥n B: Variables de Sistema
```bash
# Windows
set AWS_ACCESS_KEY_ID=AKIA...
set AWS_SECRET_ACCESS_KEY=abc123...
set AWS_REGION=us-east-1
set AWS_S3_BUCKET_NAME=extractorov-data
set S3_BASE_PATH=oficina-virtual

# Linux/Mac
export AWS_ACCESS_KEY_ID=AKIA...
export AWS_SECRET_ACCESS_KEY=abc123...
export AWS_REGION=us-east-1
export AWS_S3_BUCKET_NAME=extractorov-data
export S3_BASE_PATH=oficina-virtual
```

### 5. Verificar Configuraci√≥n

```python
# Verificar configuraci√≥n
from src.services.aws_s3_service import AWSS3Service

s3_service = AWSS3Service()
print(f"Bucket: {s3_service.bucket_name}")
print(f"Regi√≥n: {s3_service.aws_region}")
print(f"Modo simulado: {s3_service.is_simulated_mode}")

# Deber√≠a mostrar:
# Bucket: extractorov-data
# Regi√≥n: us-east-1  
# Modo simulado: False
```

### 6. Probar Conexi√≥n

```python
# Probar conectividad b√°sica
from src.services.aws_s3_service import AWSS3Service

s3_service = AWSS3Service()

# Verificar acceso al bucket
exists, metadata = s3_service.check_file_exists_in_s3("test-connectivity")
print(f"Conexi√≥n S3 exitosa: {not s3_service.is_simulated_mode}")

# Probar subida de archivo de prueba
from pathlib import Path
import json
import tempfile

# Crear archivo temporal de prueba
test_data = {"test": "connectivity", "timestamp": "2025-10-10"}
with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
    json.dump(test_data, f)
    test_file = Path(f.name)

# Subir archivo de prueba
result = s3_service.upload_file_with_registry(
    file_path=test_file,
    empresa="test",
    numero_reclamo_sgc="CONNECTIVITY_TEST"
)

print(f"Resultado de prueba:")
print(f"  - √âxito: {result.success}")
print(f"  - S3 Key: {result.s3_key}")
print(f"  - S3 URL: {result.s3_url}")
print(f"  - Upload Source: {result.upload_source}")

# Limpiar archivo temporal
test_file.unlink()
```

## Activar AWS S3 en Producci√≥n

### 1. Actualizar Managers

```python
# En afinia_manager.py y aire_manager.py

# CAMBIAR:
post_result = run_post_processing_for_company('afinia', database_only=True)

# POR:
post_result = run_post_processing_for_company('afinia', database_only=False)
```

### 2. Probar Post-Procesamiento Completo

```python
# Probar con una empresa
from src.services.post_processing_service import run_post_processing_for_company

result = run_post_processing_for_company('afinia', database_only=False)

print(f"Resultado completo:")
print(f"  BD - Insertados: {result.db_inserted}, Duplicados: {result.db_duplicates}")
print(f"  S3 - Subidos: {result.s3_uploaded}, Pre-existentes: {result.s3_pre_existing}")
print(f"  Errores: {len(result.error_messages)}")
```

### 3. Verificar Registro S3

```python
# Verificar tabla de registro S3
from src.services.aws_s3_service import AWSS3Service

s3_service = AWSS3Service()
stats = s3_service.get_s3_registry_stats()

print("Estad√≠sticas de S3 Registry:")
print(f"  Total archivos registrados: {stats['totals']['total_files']}")
print(f"  Total tama√±o: {stats['totals']['total_size_bytes'] / 1024 / 1024:.2f} MB")

for company, company_stats in stats.get('by_company_status', {}).items():
    print(f"\n  {company.upper()}:")
    for status_key, status_data in company_stats.items():
        print(f"    - {status_key}: {status_data['count']} archivos")
```

## Configuraci√≥n de Bucket Avanzada

### 1. Versioning (Recomendado)
```bash
# Habilitar versioning
aws s3api put-bucket-versioning \
  --bucket extractorov-data \
  --versioning-configuration Status=Enabled
```

### 2. Lifecycle Policy (Opcional)
```json
{
  "Rules": [
    {
      "ID": "ExtractorOVArchive", 
      "Status": "Enabled",
      "Filter": {
        "Prefix": "oficina-virtual/"
      },
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90, 
          "StorageClass": "GLACIER"
        }
      ]
    }
  ]
}
```

### 3. Bucket Policy (Opcional - Acceso Restringido)
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "RestrictToExtractorOVUser",
      "Effect": "Deny",
      "NotPrincipal": {
        "AWS": "arn:aws:iam::YOUR_ACCOUNT_ID:user/extractorov-s3-uploader"
      },
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::extractorov-data",
        "arn:aws:s3:::extractorov-data/*"
      ]
    }
  ]
}
```

## Monitoreo y Alertas

### 1. CloudWatch M√©tricas
- `NumberOfObjects`
- `BucketSizeBytes`
- `AllRequests`
- `4xxErrors`
- `5xxErrors`

### 2. Alertas Recomendadas
```json
{
  "AlarmName": "ExtractorOV-S3-HighErrorRate",
  "MetricName": "4xxErrors",
  "Namespace": "AWS/S3",
  "Statistic": "Sum",
  "Period": 300,
  "EvaluationPeriods": 2,
  "Threshold": 10,
  "ComparisonOperator": "GreaterThanThreshold"
}
```

## Troubleshooting

### Error: NoCredentialsError
```
[s3_service][client] Credenciales AWS no encontradas - habilitando modo simulado
```
**Soluci√≥n:** Verificar variables de entorno `AWS_ACCESS_KEY_ID` y `AWS_SECRET_ACCESS_KEY`

### Error: AccessDenied
```
User is not authorized to perform: s3:PutObject on resource
```
**Soluci√≥n:** Verificar pol√≠tica IAM del usuario, debe incluir permisos `s3:PutObject`

### Error: NoSuchBucket
```
The specified bucket does not exist
```
**Soluci√≥n:** Crear el bucket o verificar variable `AWS_S3_BUCKET_NAME`

### Error: InvalidRegion
```
The specified region does not exist
```
**Soluci√≥n:** Verificar variable `AWS_REGION`, usar regi√≥n v√°lida como `us-east-1`

## Comandos de Diagn√≥stico

### Verificar Conectividad AWS CLI
```bash
# Listar buckets
aws s3 ls

# Verificar acceso al bucket espec√≠fico
aws s3 ls s3://extractorov-data/

# Probar subida
echo "test" > test.txt
aws s3 cp test.txt s3://extractorov-data/test.txt
rm test.txt
```

### Verificar Desde Python
```python
import boto3
from botocore.exceptions import ClientError

try:
    s3 = boto3.client('s3')
    response = s3.list_buckets()
    print("Buckets disponibles:")
    for bucket in response['Buckets']:
        print(f"  - {bucket['Name']}")
        
    # Verificar bucket espec√≠fico
    s3.head_bucket(Bucket='extractorov-data')
    print("\nBucket 'extractorov-data' accesible ‚úÖ")
    
except ClientError as e:
    print(f"Error de AWS: {e}")
except Exception as e:
    print(f"Error: {e}")
```

## Costos Estimados

### Almacenamiento (us-east-1)
- **Standard:** $0.023 por GB/mes
- **Standard-IA:** $0.0125 por GB/mes  
- **Glacier:** $0.004 por GB/mes

### Requests
- **PUT/COPY/POST:** $0.0005 por 1,000 requests
- **GET/SELECT:** $0.0004 por 1,000 requests

### Estimaci√≥n Mensual (1000 PQRs/d√≠a)
- **Archivos:** ~30,000 archivos/mes
- **Tama√±o:** ~3 GB/mes (100 KB promedio por archivo)
- **Costo Storage Standard:** ~$0.07/mes
- **Costo Requests:** ~$0.02/mes
- **Total estimado:** ~$0.10/mes

---

**Autor:** ISES | Analyst Data Jeam Paul Arcon Solano  
**Fecha:** Octubre 2025  
**Estado:** Documentaci√≥n Completa ‚úÖ